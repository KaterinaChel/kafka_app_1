# kafka_app_1
Это учебное приложение на Python, демонстрирующее работу с Apache Kafka в отказоустойчивом кластере из 3-х нод. Система поддерживает параллельную обработку сообщений разными способами: поштучно и батчами (пачками).

Архитектура системы
Приложение состоит из следующих компонентов:
Kafka Cluster: 3 брокера (kafka1, kafka2, kafka3) для обеспечения высокой доступности.
Producer: Отправляет числовые данные, используя бинарную сериализацию.
Consumers: Группа параллельных обработчиков, разделяющих нагрузку.
Описание классов
1. KafkaSerde (Класс сериализации)
Централизованный узел для преобразования типов данных.
Методы:
serialize_int(value): Превращает целые числа Python в 8-байтовую последовательность (Big-endian) для эффективного хранения в Kafka.
deserialize_int(data): Выполняет обратное преобразование байтов в объекты Python int.
2. KafkaProducerWrapper
Обертка над высокопроизводительным продюсером confluent-kafka.
Логика: Работает в асинхронном режиме.
Метод send_messages: Генерирует поток чисел в указанном диапазоне.
Callback: Использует delivery_report для подтверждения успешной записи каждой порции данных в кластер.
3. SingleMessageConsumer
Реализует классическую модель обработки "сообщение за сообщением".
Механизм: Использует метод .poll() для получения данных.
Особенности: Подходит для задач с низкой задержкой (low latency), где каждое событие требует немедленной реакции.
4. BatchMessageConsumer
Реализует паттерн накопления данных для высокопроизводительной обработки.
Механизм: Использует метод .consume() для вычитки списка сообщений.
Логика буфера: Накапливает сообщения во внутреннем списке и запускает обработку только при достижении заданного размера (например, 10 штук).
Коммит: Подтверждает прочтение (commit) только после успешной обработки всей пачки, что гарантирует атомарность операции.

Инструкция по запуску
1. Предварительные требования
Установленный Docker и Docker Compose.
Файлы приложения и docker-compose.yml в одной директории.
2. Сборка и запуск кластера
Запустите систему в фоновом режиме:
docker-compose up --build -d

3.Создать топик (пока не прошло 60 сек иначе автоматом и без нужных паарметров)
docker exec -it kafka1 kafka-topics --create --topic topic_app --bootstrap-server kafka1:9092 --partitions 3 --replication-factor 2

4. Проверка состояния
Убедитесь, что все контейнеры (Zookeeper, 3 Kafka, UI и App) запущены:
docker-compose ps
Используйте код с осторожностью.

5. Просмотр логов обработки
Чтобы увидеть, как продюсер отправляет данные, а консьюмеры их распределяют:
bash
docker-compose logs -f kafka-app
